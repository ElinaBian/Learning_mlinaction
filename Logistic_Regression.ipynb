{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Problem -- Logistic Regression\n",
    "\n",
    "<font color = 'green'>What happens in logistic regression is we have a bunch of data, and with the data we try to build an equation to do classification for us.</font> The regression aspects means that we try to find a best-fit set of parameters.\n",
    "\n",
    "Finding the best fit is similar to regression, and in this method it’s how we train our classifier. We’ll use **optimization algorithms to find these best-fit parameters**. This best-fit stuff is where the name regression comes from. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification with logistic regression and the sigmoid function: a tractable step function\n",
    "\n",
    "We want an equation that could give all of features and predict the class. In the two-class case, the function will spit out a 0 or a 1, called Heaviside step function or sometimes just the step function. \n",
    "\n",
    "The problem with the Heaviside step function is that at the point where it steps from 0 to 1, it does so instantly. This instantaneous step is sometimes difficult to deal with. There’s another function that behaves in a similar fashion, but it’s much easier to deal with mathematically. This function is called the <font color = 'red'>**sigmoid**</font>. The sigmoid is given by the following equation:\n",
    "<font color = 'red'>$$\\sigma(z) = \\frac{1}{1+e^{-z}}$$</font>\n",
    "\n",
    "图像是y轴上缓缓从0变成了1，x=0时，y=0.5。\n",
    "\n",
    "For the logistic regression classifier, we’ll <font color = 'green'>take our features and multiply each one by a weight and then add them up as z</font>. This result will be put into the sigmoid, and we’ll <font color = 'green'>get a number between 0 and 1 as $\\sigma(z)$</font>. Anything <font color = 'green'>above 0.5 we’ll classify as 1</font>, and anything <font color = 'green'>below 0.5 we’ll classify as a 0</font>. You can also think of logistic regression as a probability estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using optimization to find the best regression coefficients\n",
    "<br>\n",
    "<font size = 3.5>The input to the sigmoid function described will be z, where z is given by the following:\n",
    "$$z = w_0x_0 + w_1x_1 +w_2x_2 +...+ w_nx_n$$\n",
    "In vector notation we can write this as <font color = 'red'>$z=w^Tx$</font>.\n",
    "<br><br>\n",
    "The vector x is our input data, and we want to find the best coefficients w, so that this classifier will be as successful as possible. In order to do that, we need to consider some ideas from optimization theory.\n",
    "</font>\n",
    "\n",
    "### 2.1 Gradient ascent 梯度上升\n",
    "\n",
    "The first optimization algorithm we’re going to look at is called gradient ascent. Gradient ascent is based on the idea that if we want to find the maximum point on a function, then **the best way to move is in the direction of the gradient**. \n",
    "<br><br>\n",
    "We write the gradient with the symbol $\\bigtriangledown$ and the gradient of a function $f(x,y)$ is given by the equation\n",
    "<br><br>\n",
    "$$\\bigtriangledown f(x,y) = \\left(\\begin{array}{c} \\frac{\\partial f(x,y)}{\\partial x} \\\\ \\frac{\\partial f(x,y)}{\\partial y} \\end{array}\\right)$$\n",
    "<br><br>\n",
    "The gradient ascent algorithm takes a step in the direction given by the gradient. The gradient operator will always point in the direction of the greatest increase. We’ve talked about direction, but I didn’t mention anything to do with **magnitude of movement**(移动量). The magnitude, or step size, we’ll take is given by the parameter $\\alpha$. In vector notation we can write the **gradient ascent algorithm** as\n",
    "<br><br>\n",
    "<font color = 'red'>$$w := w + \\alpha \\bigtriangledown_w f(w)$$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train: using gradient ascent to find the best parameters\n",
    "\n",
    "There are 100 data points and each point has two numeric features: <font color = 'blue'>$X_1$ and $X_2$</font>. We’ll try to use gradient ascent to fit the best parameters for the logistic regression model to our data. In addition, this sets the value of <font color = 'blue'>$X_0$</font> to 1.0, which is a convention we use.\n",
    "\n",
    "1.Start with the weights all set to 1.\n",
    "\n",
    "2.Repeat R number of times: \n",
    "\n",
    "(1)Calculate the gradient of the entire dataset; \n",
    "\n",
    "(2)Update the weights vector by alpha*gradient;\n",
    "\n",
    "(3)Return the weights vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_dataset():\n",
    "    data_mat = []\n",
    "    label_mat = []\n",
    "    fr = open('/Users/elinabian 1/Desktop/CU-life/summerlearning/mlinaction/dataset/testSet_chap5.txt')\n",
    "    for line in fr.readlines():\n",
    "        line_arr = line.strip().split()\n",
    "        data_mat.append([1.0, float(line_arr[0]), float(line_arr[1])])  #X0 was set to 1.0\n",
    "        label_mat.append(int(line_arr[2]))\n",
    "    return data_mat, label_mat\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "def grad_ascent(data_mat, class_labels):\n",
    "    data_matrix = np.mat(data_mat)                 #convert to NumPy matrix\n",
    "    label_mat = np.mat(class_labels).transpose()   #convert to NumPy matrix\n",
    "    m,n = np.shape(data_matrix)\n",
    "    alpha = 0.001\n",
    "    max_cycles = 500\n",
    "    weights = np.ones((n,1))\n",
    "    for k in range(max_cycles):                 #heavy on matrix operations\n",
    "        h = sigmoid(data_matrix*weights)        #matrix multiplication\n",
    "                                                #如果之前没有变成matrix，则*代表逐个元素相乘，dot才代表矩阵乘\n",
    "        error = (label_mat - h)                 #vector subtraction\n",
    "        weights = weights + alpha * data_matrix.transpose()* error      #matrix multiplication\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='/Users/elinabian 1/Desktop/CU-life/summerlearning/mlinaction/dataset/testSet_chap5.txt' mode='r' encoding='UTF-8'>\n",
      "-0.017612\t14.053064\t0\n",
      "\n",
      "-1.395634\t4.662541\t1\n",
      "\n",
      "-0.752157\t6.538620\t0\n",
      "\n",
      "-1.322371\t7.152853\t0\n",
      "\n",
      "0.423363\t11.054677\t0\n",
      "\n",
      "0.406704\t7.067335\t1\n",
      "\n",
      "0.667394\t12.741452\t0\n",
      "\n",
      "-2.460150\t6.866805\t1\n",
      "\n",
      "0.569411\t9.548755\t0\n",
      "\n",
      "-0.026632\t10.427743\t0\n",
      "\n",
      "0.850433\t6.920334\t1\n",
      "\n",
      "1.347183\t13.175500\t0\n",
      "\n",
      "1.176813\t3.167020\t1\n",
      "\n",
      "-1.781871\t9.097953\t0\n",
      "\n",
      "-0.566606\t5.749003\t1\n",
      "\n",
      "0.931635\t1.589505\t1\n",
      "\n",
      "-0.024205\t6.151823\t1\n",
      "\n",
      "-0.036453\t2.690988\t1\n",
      "\n",
      "-0.196949\t0.444165\t1\n",
      "\n",
      "1.014459\t5.754399\t1\n",
      "\n",
      "1.985298\t3.230619\t1\n",
      "\n",
      "-1.693453\t-0.557540\t1\n",
      "\n",
      "-0.576525\t11.778922\t0\n",
      "\n",
      "-0.346811\t-1.678730\t1\n",
      "\n",
      "-2.124484\t2.672471\t1\n",
      "\n",
      "1.217916\t9.597015\t0\n",
      "\n",
      "-0.733928\t9.098687\t0\n",
      "\n",
      "-3.642001\t-1.618087\t1\n",
      "\n",
      "0.315985\t3.523953\t1\n",
      "\n",
      "1.416614\t9.619232\t0\n",
      "\n",
      "-0.386323\t3.989286\t1\n",
      "\n",
      "0.556921\t8.294984\t1\n",
      "\n",
      "1.224863\t11.587360\t0\n",
      "\n",
      "-1.347803\t-2.406051\t1\n",
      "\n",
      "1.196604\t4.951851\t1\n",
      "\n",
      "0.275221\t9.543647\t0\n",
      "\n",
      "0.470575\t9.332488\t0\n",
      "\n",
      "-1.889567\t9.542662\t0\n",
      "\n",
      "-1.527893\t12.150579\t0\n",
      "\n",
      "-1.185247\t11.309318\t0\n",
      "\n",
      "-0.445678\t3.297303\t1\n",
      "\n",
      "1.042222\t6.105155\t1\n",
      "\n",
      "-0.618787\t10.320986\t0\n",
      "\n",
      "1.152083\t0.548467\t1\n",
      "\n",
      "0.828534\t2.676045\t1\n",
      "\n",
      "-1.237728\t10.549033\t0\n",
      "\n",
      "-0.683565\t-2.166125\t1\n",
      "\n",
      "0.229456\t5.921938\t1\n",
      "\n",
      "-0.959885\t11.555336\t0\n",
      "\n",
      "0.492911\t10.993324\t0\n",
      "\n",
      "0.184992\t8.721488\t0\n",
      "\n",
      "-0.355715\t10.325976\t0\n",
      "\n",
      "-0.397822\t8.058397\t0\n",
      "\n",
      "0.824839\t13.730343\t0\n",
      "\n",
      "1.507278\t5.027866\t1\n",
      "\n",
      "0.099671\t6.835839\t1\n",
      "\n",
      "-0.344008\t10.717485\t0\n",
      "\n",
      "1.785928\t7.718645\t1\n",
      "\n",
      "-0.918801\t11.560217\t0\n",
      "\n",
      "-0.364009\t4.747300\t1\n",
      "\n",
      "-0.841722\t4.119083\t1\n",
      "\n",
      "0.490426\t1.960539\t1\n",
      "\n",
      "-0.007194\t9.075792\t0\n",
      "\n",
      "0.356107\t12.447863\t0\n",
      "\n",
      "0.342578\t12.281162\t0\n",
      "\n",
      "-0.810823\t-1.466018\t1\n",
      "\n",
      "2.530777\t6.476801\t1\n",
      "\n",
      "1.296683\t11.607559\t0\n",
      "\n",
      "0.475487\t12.040035\t0\n",
      "\n",
      "-0.783277\t11.009725\t0\n",
      "\n",
      "0.074798\t11.023650\t0\n",
      "\n",
      "-1.337472\t0.468339\t1\n",
      "\n",
      "-0.102781\t13.763651\t0\n",
      "\n",
      "-0.147324\t2.874846\t1\n",
      "\n",
      "0.518389\t9.887035\t0\n",
      "\n",
      "1.015399\t7.571882\t0\n",
      "\n",
      "-1.658086\t-0.027255\t1\n",
      "\n",
      "1.319944\t2.171228\t1\n",
      "\n",
      "2.056216\t5.019981\t1\n",
      "\n",
      "-0.851633\t4.375691\t1\n",
      "\n",
      "-1.510047\t6.061992\t0\n",
      "\n",
      "-1.076637\t-3.181888\t1\n",
      "\n",
      "1.821096\t10.283990\t0\n",
      "\n",
      "3.010150\t8.401766\t1\n",
      "\n",
      "-1.099458\t1.688274\t1\n",
      "\n",
      "-0.834872\t-1.733869\t1\n",
      "\n",
      "-0.846637\t3.849075\t1\n",
      "\n",
      "1.400102\t12.628781\t0\n",
      "\n",
      "1.752842\t5.468166\t1\n",
      "\n",
      "0.078557\t0.059736\t1\n",
      "\n",
      "0.089392\t-0.715300\t1\n",
      "\n",
      "1.825662\t12.693808\t0\n",
      "\n",
      "0.197445\t9.744638\t0\n",
      "\n",
      "0.126117\t0.922311\t1\n",
      "\n",
      "-0.679797\t1.220530\t1\n",
      "\n",
      "0.677983\t2.556666\t1\n",
      "\n",
      "0.761349\t10.693862\t0\n",
      "\n",
      "-2.168791\t0.143632\t1\n",
      "\n",
      "1.388610\t9.341997\t0\n",
      "\n",
      "0.317029\t14.739025\t0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 理解一下数据格式\n",
    "\n",
    "fr = open('/Users/elinabian 1/Desktop/CU-life/summerlearning/mlinaction/dataset/testSet_chap5.txt')\n",
    "print(fr)\n",
    "\n",
    "for line in fr.readlines():\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, -0.017612, 14.053064], [1.0, -1.395634, 4.662541], [1.0, -0.752157, 6.53862], [1.0, -1.322371, 7.152853], [1.0, 0.423363, 11.054677], [1.0, 0.406704, 7.067335], [1.0, 0.667394, 12.741452], [1.0, -2.46015, 6.866805], [1.0, 0.569411, 9.548755], [1.0, -0.026632, 10.427743]]\n",
      "[0, 1, 0, 0, 0, 1, 0, 1, 0, 0]\n",
      "[[ 1.       -0.017612 14.053064]\n",
      " [ 1.       -1.395634  4.662541]\n",
      " [ 1.       -0.752157  6.53862 ]\n",
      " [ 1.       -1.322371  7.152853]\n",
      " [ 1.        0.423363 11.054677]\n",
      " [ 1.        0.406704  7.067335]\n",
      " [ 1.        0.667394 12.741452]\n",
      " [ 1.       -2.46015   6.866805]\n",
      " [ 1.        0.569411  9.548755]\n",
      " [ 1.       -0.026632 10.427743]]\n",
      "(100, 3)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "data_arr, label_mat = load_dataset()\n",
    "print(data_arr[:10])\n",
    "print(label_mat[:10])\n",
    "\n",
    "\n",
    "# 理解一下Numpy matrix\n",
    "data_matrix = np.mat(data_arr)\n",
    "print(data_matrix[:10])\n",
    "print(np.shape(data_matrix))\n",
    "label_mat = np.mat(label_mat).transpose() \n",
    "print(np.shape(label_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.12414349]\n",
      " [ 0.48007329]\n",
      " [-0.6168482 ]]\n"
     ]
    }
   ],
   "source": [
    "# calculate weights\n",
    "data_arr, label_mat = load_dataset()\n",
    "grad_ascent(data_arr, label_mat)\n",
    "weights = grad_ascent(data_arr, label_mat)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Analyze: plotting the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_best_fit(weights):\n",
    "    import matplotlib.pyplot as plt\n",
    "    data_mat, label_mat = load_dataset()\n",
    "    weights = weights.getA()         # return self as an ndarray object; equivalent to np.asarray(self).\n",
    "    data_arr = np.array(data_mat)\n",
    "    n = np.shape(data_arr)[0] \n",
    "    x_cord1 = []\n",
    "    y_cord1 = []\n",
    "    x_cord2 = []\n",
    "    y_cord2 = []\n",
    "    for i in range(n):\n",
    "        if int(label_mat[i])== 1:    # class 1--red, mark--s; class 2--green\n",
    "            x_cord1.append(data_arr[i,1])\n",
    "            y_cord1.append(data_arr[i,2])\n",
    "        else:\n",
    "            x_cord2.append(data_arr[i,1])\n",
    "            y_cord2.append(data_arr[i,2])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(x_cord1, y_cord1, s=30, c='red', marker='s')\n",
    "    ax.scatter(x_cord2, y_cord2, s=30, c='green')\n",
    "    x = np.arange(-3.0, 3.0, 0.1)\n",
    "    y = (-weights[0]-weights[1]*x)/weights[2]\n",
    "    ax.plot(x, y)\n",
    "    plt.xlabel('X1'); plt.ylabel('X2')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_best_fit(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.00000000e+00, -9.00000000e-01, -8.00000000e-01, -7.00000000e-01,\n",
       "       -6.00000000e-01, -5.00000000e-01, -4.00000000e-01, -3.00000000e-01,\n",
       "       -2.00000000e-01, -1.00000000e-01, -2.22044605e-16,  1.00000000e-01,\n",
       "        2.00000000e-01,  3.00000000e-01,  4.00000000e-01,  5.00000000e-01,\n",
       "        6.00000000e-01,  7.00000000e-01,  8.00000000e-01,  9.00000000e-01])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 关于np.arange\n",
    "\n",
    "x = np.arange(-1, 1, 0.1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
